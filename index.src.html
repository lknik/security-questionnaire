<h1>Self-Review Questionnaire: Security and Privacy</h1>
<pre class="metadata">
Status: DREAM
ED: https://w3ctag.github.io/security-questionnaire/
Shortname: security-privacy-questionnaire
Level: 1
Editor: Mike West, Google Inc., mkwst@google.com
Group: tag
Indent: 2
Abstract:
This document provides a points to help in considering the privacy impact of a new feature or
  specification. The questions are meant to be useful when considering the security and privacy
  aspects of a new feature or specification. The respective points should be addressed by
  representatives (e.g. editors) behind the new proposal or a feature.
  Given the variety and nature of specifications, it is likely that the listed questions will not be
  comprehensive in a way enabling to reason about the full privacy impact.
  It is nonetheless the aim to present the questions as a useful point, helping to consider security
  and privacy at the start of work on a new feature.

  It is not meant as a "security checklist", nor does an editor or group’s use of this questionnaire
  obviate the editor or group’s responsibility to obtain "wide review" of a specification security
  and privacy properties before publication. Furthermore, the filled questionnaire should not be
  understood as security and privacy considerations, although part of the answers may be relevant in
  drafting the considerations.

Version History: https://github.com/w3ctag/security-questionnaire/commits/master/index.src.html
!Bug Reports: <a href="https://github.com/w3ctag/security-questionnaire/issues/new">via the w3ctag/security-questionnaire repository on GitHub</a>
</pre>

<!-- Big Text: Intro -->
<section>
  <h2 id="intro">Introduction</h2>

  Adding features to the web is a tricky thing; on the one hand, we want to
  provide developers with access to all the things they need in order to build
  amazing experiences. On the other, we need to ensure that we don't
  accidentally hand over too much power to malicious folks who could abuse it,
  or unintentionally expose people's private data without adequate controls.
  Ideally, careful review of every specification we publish will allow us to
  strike the right balance.

  Working groups can (and should) begin this review process early, of course.
  It's <em>easy</em> to mitigate risks to users on the web <em>before</em> a
  feature is finalized and shipped in user agents. Changing APIs or
  introducing restrictions becomes nigh impossible once the web begins to
  depend on a particular implementation.

  This document encourages early review by posing a number of questions that
  you as a individual reader of a specification can ask—and that working
  groups and spec editors might consider themselves, before asking for more
  formal review. The intent is to highlight areas which have historically had
  interesting implications on a user's security or privacy, and thereby to
  focus the editor's attention and working group's attention and reviewers'
  attention on areas that might previously have been overlooked.

  Note: Answering these questions obviously doesn't constitute "wide review" in
  and of itself, but could provide a helpful basis of understanding upon which
  future reviewers can build.
</section>

<!-- Big Text: Threats -->
<section>
  <h2 id="threats">Threat Models</h2>

  "Security" and "Privacy" are big concepts. In order to pare them down to
  something which could feasibly guide working groups' decisions, let's consider
  the types of threats to both which the web makes possible:

  <h3 id="passive-network">Passive Network Attackers</h3>

  A <dfn>passive network attacker</dfn> has read-access to the bits going over
  the wire between users and the servers they're communicating with. She can't
  <em>modify</em> the bytes, but she can collect and analyze them.

  Due to the decentralized nature of the internet, and the general level of
  interest in user activity, it's reasonable to assume that practically every
  unencrypted bit that's bouncing around the network of proxies, routers, and
  servers you're using right now is being read by someone. It's equally likely
  that some of these attackers are doing their best to understand the encrypted
  bits as well (though that requires significantly more effort).

  *   The IETF's "Pervasive Monitoring Is an Attack" document [[RFC7258]] is
      useful reading, outlining some of the impacts on privacy that this
      assumption entails.

  *   Governments aren't the only concern; your local coffee shop is likely to
      be gathering information on its customers, your ISP at home is likely to
      be doing the same.

  <h3 id="active-network">Active Network Attackers</h3>

  An <dfn>active network attacker</dfn> has both read- and write-access to the
  bits going over the wire between users and the servers they're communicating
  with. She can collect and analyze data, but also modify it in-flight,
  injecting and manipulating JavaScript and HTML at will. This is more common
  than you might expect, for both benign and malicious purposes:

  *   ISPs and caching proxies regularly cache and compress images before
      delivering them to users in an effort to reduce data usage. This can be
      especially useful for users on low-bandwidth, high-latency devices like
      phones.

  *   ISPs also regularly inject JavaScript [[COMCAST]] and other identifiers
      [[VERIZON]] for less benign purposes.

  *   If your ISP is willing to modify substantial amounts of traffic flowing
      through it for profit, it's difficult to believe that state-level
      attackers will remain passive.

  <h3 id="sop-violations">Same-Origin Policy Violations</h3>

  The <dfn>same-origin policy</dfn> is the cornerstone of security on the web;
  one origin should not have direct access to another origin's data (the policy
  is more formally defined in Section 3 of [[RFC6454]]). A corollary to this
  policy is that an origin should not have direct access to data that isn't
  associated with <em>any</em> origin: the contents of a user's hard drive,
  for instance. Various kinds of attacks bypass this protection in one way or
  another. For example:

  *   <dfn local-lt="XSS">Cross-site scripting attacks</dfn> involve an
      attacker tricking an origin into executing attacker-controlled code in
      the context of a target origin.

  *   <dfn local-lt="CSRF">Cross-site request forgery attacks</dfn> trick
      user agents into exerting a user's ambient authority on sites where
      they've logged in by submitting requests on their behalf.

  *   Data leakage occurs when bits of information are inadvertantly made
      available cross-origin, either explicitly via CORS headers [[CORS]],
      or implicitly, via side-channel attacks like [[TIMING]].

  <h3 id="third-party-tracking">Third-Party Tracking</h3>

  ISSUE(w3ctag/security-questionnaire#7): Flesh this out.

</section>

<!-- Big Text: Questions -->
<section>
  <h2 id="questions">Questions to Consider</h2>

  <h3 id="pii">
    Does this specification deal with personally-identifiable information?
  </h3>

  <dfn local-lt="personally-identifiable">Personally-identifiable
  information</dfn> (PII) includes a large swath of data which could be used on
  its own, or in combination with other information, to identify a single
  person. The exact definition of what's considered PII varies from jurisdiction
  to jurisdiction, but could certainly include things like a home address, an
  email address, birthdates, usernames, fingerprints etc. Wikipedia has a fairly
  good description at [[PII]].

  If the specification under consideration exposes PII to the web, it's
  important to consider ways to mitigate the obvious impacts. For instance:

  *   A feature which uses biometric data (fingerprints or retina scans) could
      refuse to expose the raw data to the web, instead using the raw data only
      to unlock some origin-specific and ephemeral secret and transmitting that
      secret instead.

  *   User mediation could be required, in order to ensure that no data is
      exposed without a user's explicit choice (and hopefully understanding).

  <h3 id="credentials">
    Does this specification deal with high-value data?
  </h3>

  Data which isn't <a>personally-identifiable</a> can still be quite valuable.
  Sign-in credentials (like username/password pairs, or OAuth refresh tokens)
  can be extrememly powerful in the wrong hands, as can financial instruments
  like credit card data. Making this data available to JavaScript, for instance,
  could expose it to <a>XSS</a> attacks and <a>active network attackers</a> who
  could inject code to read and exfiltrate the data. For instance:

  *   Credential Management [[CREDENTIAL-MANAGEMENT]] allows sites to request
      a user's credentials from a user agent's password manager in order to
      sign the user in quickly and easily. This opens the door for abuse, as
      a single XSS vulnerability could expose user data trivially to
      JavaScript. The Credential Managerment API mitigates
      the risk by offering the username and password as only an opaque
      <code>FormData</code> object which cannot be directly read by JavaScript
      and strongly suggests that authors use Content Security Policy [[CSP]] with
      resonable <code>connect-src</code> and <code>form-action</code> values to
      further mitigate the risk of exfiltration.

  <h3 id="persistent-origin-specific-state">
    Does this specification introduce new state for an origin that persists
    across browsing sessions?
  </h3>

  For example:

  *   Service Worker [[SERVICE-WORKERS]] intercept all requests made by an
      origin, allowing sites to function perfectly even when offline. A
      maliciously-injected service worker, however, would be devastating (as
      documented in that spec's
      <a href="http://www.w3.org/TR/service-workers/#security-considerations">security
      considerations section</a>). They mitigate the risks an <a>active network
      attacker</a> or <a>XSS</a> vulnerability present by requiring an
      encrypted and authenticated connection in order to register a service
      worker.

  *   Platform-specific DRM implementations might expose origin-specific
      information in order to help identify users and determine whether they
      ought to be granted access to a specific piece of media. These kinds of
      identifiers should be carefully evaluated to determine how abuse can be
      mitigated; identifiers which a user cannot easily change are very
      valuable from a tracking perspective, and protecting the identifiers from
      an active network attacker is an important concern.

  *   Cookies, <code>ETag</code>, <code>Last Modified</code>, <code>Local
      Storage</code>, <code>Indexed DB</code>, etc. all allow an origin to
      store information about a user, and retrieve it later, directly or
      indirectly. User agents mitigate the risk that these kinds of storage
      mechanisms will form a persistent identifier by offering users the
      ability to wipe out the data contained in these types of storage.

  <h3 id="persistent-identifiers">
    Does this specification expose persistent, cross-origin state to the web?
  </h3>

  For example:

  *   The <code>GL_RENDERER</code> string exposed by some WebGL implementations
      improves performance in some kinds of applications, but does so at the
      cost of adding persistent state to a user's fingerprint. These kinds of
      device-level details should be carefully weighed to ensure that the costs
      are outweighed by the benefits.

  *   The {{NavigatorPlugins}} list exposed via the DOM practically never
      changes for most users. Some user agents have taken steps to reduce the
      entropy introduced by
      <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=757726">disallowing
      direct enumeration of the plugin list</a>.

  <h3 id="other-data">
    Does this specification expose any other data to an origin that it doesn't
    currently have access to?
  </h3>

  As noted above in [[#sop-violations]], the <a>same-origin policy</a> is an
  important security barrier that new features need to carefully consider.
  If a specification exposes details about another origin's state, or allows
  POST or GET requests to be made to another origin, the consequences can be
  severe.

  *   Content Security Policy [[CSP]] unintentionally exposed redirect targets
      cross-origin by allowing one origin to infer details about another origin
      through violation reports (see [[HOMAKOV]]). The working group eventually
      mitigated the risk by reducing a policy's granularity after a redirect.

  *   Beacon [[BEACON]] allows an origin to send POST requests to an endpoint
      on another origin. They decided that this feature didn't add any new
      attack surface above and beyond what normal form submission entails, so
      no extra mitigation was necessary.

  <h3 id="string-to-script">
    Does this specification enable new script execution/loading mechanisms?
  </h3>

  * HTML Imports [[HTML-IMPORTS]] create a new script-loading mechanism, using
    <{link}> rather than <{script}>, which might be easy to overlook when
    evaluating an application's attack surface. The working group notes this
    risk, and ensured that they required reasonable interactions with Content
    Security Policy's <code>script-src</code> directive.

  * New string-to-script mechanism? (e.g. `eval()` or `setTimeout([string], ...)`)

  * What about style?

  <h3 id="location">Does this specification allow an origin access to a user's location?</h3>

  A user's location is highly-desirable information for a variety of use cases.
  It is also, understandably, information which many users are reluctant to
  share, as it can be both highly identifying, and potentially creepy. New
  features which make use of geolocation information, or which expose it to the
  web in new ways should carefully consider the ways in which the risks of
  unfettered access to a user's location could be mitigated. For instance:

  *   Geolocation information can serve many use cases at a much less granular
      precision than the user agent can offer. For instance, a resturaunt
      recommendation can be generated by asking for a user's city-level location
      rather than a position accurate to the centimeter.

  *   A recent Geofencing proposal [[GEOFENCING]] ties itself to service workers
      and therefore to encrypted and authenticated origins.

  <h3 id="sensors">Does this specification allow an origin access to sensors on a user's device?</h3>

  ISSUE: TODO.

  <h3 id="local-device">Does this specification allow an origin access to aspects of a user's local computing environment?</h3>

  (e.g. screen sizes, installed fonts, installed plugins, bluetooth or network interface identifiers)?

  ISSUE: TODO.

  <h3 id="remote-device">
    Does this specification allow an origin access to other devices?
  </h3>

  Accessing other devices, both via network connections and via
      direct connection to the user's machine (e.g. via Bluetooth,
      NFC, or USB), could expose vulnerabilities - some of
      these devices were not created with web connectivity in mind and may be inadequately
      hardened against malicious input.

  *   The Network Service Discovery API [[DISCOVERY]] recommends CORS preflights
      before granting access to a device, and requires user agents to involve
      the user with a permission request of some kind. The spec's
      <a href="https://dvcs.w3.org/hg/dap/raw-file/tip/discovery-api/Overview.html#security-and-privacy-considerations">Security
      and privacy considerations"</a> section has more details.

  *   Likewise, the Web Bluetooth [[BLUETOOTH]] has an extensive discussion of
      <a href="https://webbluetoothcg.github.io/web-bluetooth/#security-and-privacy-considerations">"Security
      and privacy considerations"</a>, which is worth reading as an example for
      similar work.

      Direct connections might be also
      be used to bypass security checks that other APIs would provide.  For example:

      * Attackers used the WebUSB API to access others sites' crendentials on a hardware security,
      bypassing same-origin checks in an early U2F API.  [[YUBIKEY-ATTACK]]

  <h3 id="native-ui">
    Does this specification allow an origin some measure of control over a user
    agent's native UI?
  </h3>

  (showing, hiding, or modifying certain details, especially if those details are relevant to security)?

  ISSUE: TODO.

  <h3 id="temporary-id">Does this specification expose temporary identifiers to the web?</h3>

  (e.g. TLS features like Channel ID, session identifiers/tickets, etc)?

  ISSUE: TODO.

  <h3 id="first-third-party">Does this specification distinguish between behavior in first-party and third-party contexts?</h3>

  *   Section 2.1 of [[FIRST-PARTY-ONLY]] defines "first-party" in line with
      existing browser behavior (Chrome and Firefox).

  <h3 id="private-browsing">
    How should this specification work in the context of a user agent's
    private browsing mode?
  </h3>

  *   Ideally, the feature would work in such a way that the website would not
      be able to determine that the user was in private browsing mode.

  *   Less ideally, the feature wouldn't work, but the website still wouldn't
      be able to distinguish a private browsing context from simply being denied
      permission to use the feature (for instance).

  *   Unideally, the feature wouldn't exist at all in private browsing mode, which
      means that the user wouldn't be exposing data, but the website can probably
      tell that the user is in that state.

  <h3 id="storage">
    Does this specification persist data to a user's local device?
  </h3>

  *   How should user agent's "Clear browsing data" functionality work with
      this data? Are there caches that the user agent needs to be particularly
      careful with?

  <h3 id="considerations">
    Does this specification have a "Security Considerations" and "Privacy
    Considerations" section?
  </h3>

  Interesting features added to the web platform generally have security and/or
  privacy impacts. Documenting the various concerns and potential abuses in
  "Security Considerations" and "Privacy Considerations" sections of a document
  is a good way to help implementers and web developers understand the risks
  that a feature presents, and to ensure that adequate mitigations are in place.

  If it seems like a feature does not have security or privacy impacts,
  then say so inline in the spec section for that feature:

  <blockquote>
    There are no known security or privacy impacts of this feature.
  </blockquote>

  Saying so explicitly in the specification serves several purposes:
  <ol>
    <li>
      Shows that a spec author/editor has explicitly considered security and
      privacy when designing a feature.
    </li>
    <li>
      Provides some sense of confidence that there are no such impacts.
    </li>
    <li>
      Challenges security and privacy minded individuals to think of and find
      even the potential for such impacts.
    </li>
    <li>
      Demonstrates the spec author/editor's receptivity to feedback about such
      impacts.
    </li>
  </ol>

  <h3 id="relaxed-sop">
    Does this specification allow downgrading default security characteristics?
  </h3>

  *   <code>document.domain</code>
  *   [[CORS]]
  *   [[WEBMESSAGING]]
  *   <code>referrer 'unsafe-always'</code>

</section>

<section>
  <h2 id="mitigations">
    Mitigation Strategies
  </h2>

  <h3 id="secure-contexts">
    Secure Contexts
  </h3>

  In the presence of an <a>active network attacker</a>, offering a feature to
  an insecure origin is the same as offering that feature to every origin (as
  the attacker can inject frames and code at will). Requiring an encrypted and
  authenticated connection in order to use a feature can mitigate this kind of
  risk.

  <h3 id="user-mediation">
    Explicit user mediation
  </h3>

  If a feature has privacy or security impacts that are endemic to the feature
  itself, then one valid strategy for exposing it to the web is to require user
  mediation before granting an origin access. For instance, [[GEOLOCATION-API]]
  reveals a user's location, and wouldn't be particularly useful if it didn't;
  user agents generally gate access to the feature on a permission prompt which
  the user may choose to accept.

  Designing such prompts is difficult. Choosers are good. Walls of text are bad.

  ISSUE: Bring in some of felt@'s ideas here.

  <h3 id="drop-feature">
    Drop the feature
  </h3>

  One way to mitigate the risks that a feature presents is to remove it from
  a specification.

  <div class="example">
    The easiest way to mitigate potential negative security or privacy
    impacts of a feature, and even discussing the possibility,
    is to drop the feature.

    Every feature in a spec should be considered guilty
    (of harming security and/or privacy) until proven otherwise.
    Every specification should seek to be as small as possible,
    even if only for the reasons of reducing and minimizing
    security/privacy attack surface(s).

    By doing so we can reduce the overall security (and privacy) attack surface
    of not only a particular feature, but of a module (related set of features),
    a specification, and the overall web platform.

    Ideally this is one of many motivations to reduce each of those to the minimum viable:

    <ol>
      <li>
      Minimum viable feature:
      cut/drop values, options, or optional aspects.
      </li>
      <li>
      Minimum viable web format/protocol/API:
      cut/drop a module, or even just one feature.
      </li>
      <li>
      Minimum viable web platform:
      Cut/drop/obsolete entire specification(s).
      </li>
    </ol>

    ISSUE: Move Tantek's thoughts somewhere. They don't really fit well here,
    though the sentiment of a minimum viable web platform might fit into some
    other TAG finding.
  </div>
</section>

<pre class="anchors">
urlPrefix: http://www.w3.org/TR/html5/
  type: interface
    urlPrefix: webappapis.html
      text: NavigatorPlugins
</pre>

<pre class="link-defaults">
spec:html5; type:element; text:script
</pre>

<pre class="biblio">
{
  "BLUETOOTH": {
      "href": "https://webbluetoothcg.github.io/web-bluetooth/",
      "title": "Web Bluetooth",
      "publisher": "W3C",
      "authors": [ "Jeffrey Yasskin", "Vincent Scheib" ]
  },
  "COMCAST": {
      "href": "http://arstechnica.com/tech-policy/2014/09/why-comcasts-javascript-ad-injections-threaten-security-net-neutrality/",
      "title": "Comcast Wi-Fi serving self-promotional ads via JavaScript injection",
      "publisher": "Ars Technica",
      "authors": [ "David Kravets" ]
  },
  "CREDENTIAL-MANAGEMENT": {
      "href": "https://w3c.github.io/webappsec/specs/credentialmanagement/",
      "title": "Credential Management",
      "publisher": "W3C",
      "authors": [ "Mike West" ]
  },
  "DISCOVERY": {
      "href": "http://dvcs.w3.org/hg/dap/raw-file/tip/discovery-api/Overview.html",
      "title": "Network Service Discovery",
      "authors": [ "Rich Tibbett" ],
      "publisher": "W3C"
  },
  "GEOFENCING": {
      "href": "https://github.com/slightlyoff/Geofencing/blob/master/explainer.md",
      "title": "Geofencing Explained",
      "authors": [ "Alex Russell" ]
  },
  "HOMAKOV": {
      "href": "http://homakov.blogspot.de/2014/01/using-content-security-policy-for-evil.html",
      "title": "Using Content-Security-Policy for Evil",
      "authors": [ "Egor Homakov" ]
  },
  "VERIZON": {
      "href": "http://adage.com/article/digital/verizon-target-mobile-subscribers-ads/293356/",
      "title": "Verizon looks to target its mobile subscribers with ads",
      "publisher": "Advertising Age",
      "authors": [ "Mark Bergen", "Alex Kantrowitz" ]
  },
  "PII": {
      "href": "https://en.wikipedia.org/wiki/Personally_identifiable_information",
      "title": "Personally identifiable information",
      "publisher": "Wikipedia"
  },
  "TIMING": {
      "href": "http://www.contextis.com/documents/2/Browser_Timing_Attacks.pdf",
      "title": "Pixel Perfect Timing Attacks with HTML5",
      "authors": [ "Paul Stone" ],
      "publisher": "Context Information Security"
  },
  "RFC6454": {
      "href": "https://tools.ietf.org/html/rfc6454",
      "title": "The Web Origin Concept",
      "authors": [ "Adam Barth" ],
      "publisher": "IETF"
  },
  "RFC7258": {
      "href": "http://tools.ietf.org/html/rfc7258",
      "title": "Pervasive Monitoring Is an Attack",
      "authors": [ "Stephen Farrell", "Hannes Tschofenig" ],
      "publisher": "IETF"
  },
  "FIRST-PARTY-ONLY": {
      "href": "https://tools.ietf.org/html/draft-west-first-party-cookies",
      "title": "'First-Party-Only' Cookies",
      "authors": [ "Mike West" ],
      "publisher": "IETF"
  },
  "YUBIKEY-ATTACK": {
      "href": "https://www.wired.com/story/chrome-yubikey-phishing-webusb/",
      "title": "Chrome Lets Hackers Phish Even 'Unphishable' YubiKey Users",
      "authors": [ "Andy Greenberg" ],
      "publisher": "Wired"
}
</pre>
